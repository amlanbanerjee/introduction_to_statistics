[["index.html", "Introduction to Statistics Chapter 1 Course Information 1.1 Course Description 1.2 Course Outcomes", " Introduction to Statistics Amlan Banerjee, Ph.D. 2021-12-30 Chapter 1 Course Information The purpose of this elementary statistics course is to introduce students to the relationship between statistics and the world through use of a wide variety of real applications that bring life to theory and methods. 1.1 Course Description The course covers sampling methods, classification of data, probability, frequency and probability distributions, confidence intervals, tests of statistical significance, and simple regression and correlation. 1.2 Course Outcomes Upon successful completion of this course, the student will be able to: Interpret quantitative data using graphs and descriptive statistics with emphasis on histograms and boxplots. Compute measures of expectation and variation for a discrete probability distribution Compute probability for a binomial and normal distribution. Perform calculations to estimate parameters using confidence intervals based on the normal distribution and \\(t\\)-distribution. Perform hypotheses testing involving a sample mean, proportion, and standard deviation/variance Perform hypotheses testing involving two sample means (independent and dependent), two population proportions, and two standard deviations/variances. Construct linear regression models and correlation coefficients from datasets. "],["introduction.html", "Chapter 2 Introduction 2.1 What is Statistics? 2.2 Statistical Thinking 2.3 Types of Data or Variable 2.4 Sampling Methods 2.5 Sampling Errors 2.6 Bias and Precision 2.7 Observational Studies 2.8 Experimental Design", " Chapter 2 Introduction Learning Outcome: Select a suitable sampling design {simple random, systematic, stratified, cluster}, given information about the observational study or experiment. The chapter introduces various data types, sampling techniques, sampling errors, two main types of statistical studies, namely observational studies and experiments. Also discussed here are their benefits and drawbacks and how to design them well. 2.1 What is Statistics? The science of planning studies and experiments; obtaining data; and organizing, summarizing, presenting, analyzing, and interpreting those data and then drawing conclusions based on them. Application of statistics is literally everywhere - business, finance, engineering, health science, social science, environmental science, politics, education, and so on. 2.2 Statistical Thinking Statistical studies are designed by the following five steps: Raise a precise question about one or more variables. Design a plan to answer the question. Collect the data. Analyze the data. Draw a conclusion from the data about the question. Definitions Data are collections of obervations, such as measurements or survey responses. Variable is a characteristics of the individuals to be measured or observed. Population is the complete collection of all measurements or data that are being considered. Typically, a population is the complete collection of data that we would like to make inference about. Census is the collection of data from every member of the population. Sampling Frame is a numbered list of all the individuals in the population from which a sample is drawn. Sample is a sub-collection of members selected from a population. Population Parameter is a numerical measurement describing some characteristics of a population. Sample Statistic is a numerical measurement describing some characteristics of a sample. Example (parameter vs. statistic): There are \\(17,246,372\\) high school students in the U.S. In a study of \\(8505\\) U.S. high school students \\(16\\) years of age or older, \\(44.5\\%\\) of them said that they texted while driving at least once during the previous \\(30\\) days. Parameter: What percent of the population texted while driving? (unknown) Statistic: \\(44.5\\%\\) 2.3 Types of Data or Variable Categorical (or Qualitative) - consist of names or labels (not numbers that represent counts or measurements) Levels of Measurement of Qualitative Data - Nominal (unordered): the data fall into categories that have no particular order or ranking in relation to each other, e.g., color (blue, green, red,), gender (male, female), nationality (American, Canadian, Mexican,) - Ordinal (ordered): values have a natural order to ranking, but differences either cant be found or are meaningless e.g., temperature (low, medium, high), exam grade (A, B, C, D, F), satisfaction (high, neutral, low) Numerical (or Quantitative) - consist of numbers representing measurements or counts. - Continuous: a subject or observation takes a value from an interval of real numbers, e.g., weight, height, age, etc. Continuous (numerical) data result from infinitely many possible quantitative values, where the collection of values is not countable, such as the lengths of distances from \\(0\\) inch to \\(12\\) inch. - Discrete: a subject or observation takes certain values from a finite set, e.g. population, traffic volume, etc. Discrete data result when values are quantitative and the number of values is finite, or countable, such as the number of tosses of a coin before getting tails. Levels of Measurement of Quantitative Data Interval Variables: these variables are measured along a continuum, and they have the property that equal differences between measures represent equal differences in the values of the variable. Therefore, differences are meaningful, but there is no natural zero starting point and ratios are meaningless. For example, temperature is measured in degrees Celsius. So the difference between \\(20^\\circ C\\) and \\(30^\\circ C\\) is the same as \\(30^\\circ C\\) to \\(40^\\circ C\\). However, \\(0^\\circ C\\) does not mean there is no temperature. Also, \\(\\dfrac{40^\\circ C}{20^\\circ C} = 2\\) does not mean \\(40^\\circ C\\) is twice the warmer than \\(20^\\circ C\\). Similarly the years 2021 and when you were born, say 1981, can be arranged in order, and the difference of \\(40\\) years can be found and is meaningful. However, time did not begin in year \\(0\\), so the year \\(0\\) is arbitrary instead of being a natural zero starting point representing no time. Ratio Variables: these variables have all the properties of interval variables, but in addition have the property that there is a natural zero starting point and the ratios make sense. Examples of ratio variables include height, mass, distance, time etc. The name ratio reflects the fact that you can use the ratio of measurements. So, for example, a distance of \\(10\\) meters is twice the distance of \\(5\\) meters, and the measurement of distance starts at \\(0\\). 2.4 Sampling Methods Sampling from a Population Because populations are often very large, a common objective of the use of statistics is to obtain data from a sample and then use those data to form a conclusion about the population. Example: Identify the Variable, Sample, and Population of a Study In a poll of \\(1000\\) randomly selected American adults, \\(48\\%\\) of respondents said that they strongly disapprove of the way Congress is doing its job. The study then made an inference about all American adults. Define the variable of the study. Identify the sample. Identify the population. 2.4.1 Simple Random Sampling (SRS) A simple random sample of \\(n\\) subjects is selected in such a way that every possible sample of the sample size \\(n\\) has the same chance of being chosen. In statistics a sample of a population is said to be random if each member in the population has an equal chance of being chosen. Sampling with replacement - an individual is selected more than once. Sampling without replacement - an individual is selected only once. Source: OpenIntro.Org 2.4.2 Stratified Sampling The population is divided into non-overlapping, homogeneous subgroups called strata . Then, SRS is employed to select a certain number or a certain proportion of the whole within each stratum. Source: OpenIntro.Org Example: Stratified Sampling (Optional) Design a sample to survey \\(500\\) students using stratified sampling method. \\[ \\text { Strata Sizes } \\bbox[white,4px] { \\color{black} { \\begin{array}{c|c|c|c} \\text{Gender} &amp; \\text{Undergraduate} &amp; \\text{Graduate} &amp; \\text{Total} \\\\ \\hline \\text{Female} &amp; \\text{3355} &amp; \\text{4693} &amp; \\text{8048} \\\\ \\text{Male} &amp; \\text{3734} &amp; \\text{6687} &amp; \\text{10421} \\\\ \\hline \\text{Total} &amp; \\text{7089} &amp; \\text{11380} &amp; \\text{18469} \\\\ \\end{array} } } \\] \\[ \\text { Strata Proportions } \\bbox[yellow,4px] { \\color{black} { \\begin{array}{c|c|c|c} \\text{Gender} &amp; \\text{Undergraduate} &amp; \\text{Graduate} &amp; \\text{Total} \\\\ \\hline \\text{Female} &amp; \\text{3355/18469 = .182} &amp; \\text{.254} &amp; \\text{.436} \\\\ \\text{Male} &amp; \\text{.202} &amp; \\text{.362} &amp; \\text{.564} \\\\ \\hline \\text{Total} &amp; \\text{.384} &amp; \\text{.616} &amp; \\text{1.000} \\\\ \\end{array} } } \\] \\[ \\text { Sample sizes } \\bbox[lightblue,4px] { \\color{black} { \\begin{array}{c|c|c|c} \\text{Gender} &amp; \\text{Undergraduate} &amp; \\text{Graduate} &amp; \\text{Total} \\\\ \\hline \\text{Female} &amp; \\text{.182(500)=91} &amp; \\text{127} &amp; \\text{218} \\\\ \\text{Male} &amp; \\text{101} &amp; \\text{181} &amp; \\text{282} \\\\ \\hline \\text{Total} &amp; \\text{192} &amp; \\text{308} &amp; \\text{500} \\\\ \\end{array} } } \\] Practice Design a sample to survey \\(1200\\) students using stratified sampling method. \\[ \\bbox[white,4px] { \\color{black} { \\begin{array}{c|c|c|c} \\text{Gender} &amp; \\text{Undergraduate} &amp; \\text{Graduate} &amp; \\text{Professional} \\\\ \\hline \\text{Female} &amp; \\text{10588} &amp; \\text{4475} &amp; \\text{1421} \\\\ \\text{Male} &amp; \\text{7762} &amp; \\text{3736} &amp; \\text{1153} \\\\ \\hline \\end{array} } } \\] 2.4.3 Cluster Sampling The population is often divided into non-overlapping mutually homogeneous yet internally heterogeneous subgroups called clusters. Cluster sampling is much like SRS, but instead of randomly selecting individuals, SRS is applied to select clusters. In other words, unlike stratified sampling, cluster sampling is most helpful when there is a lot of case-to-case variability within a cluster but the clusters themselves dont look very different from one another. That is, we expect strata to be self-similar (homogeneous), while we expect clusters to be diverse (heterogeneous). The elements in each cluster are then sampled. If all elements in each sampled cluster are sampled, then this is referred to as a one-stage cluster sampling plan. Sometimes cluster sampling can be a more economical random sampling technique than the alternatives. For example, if neighborhoods represented clusters, this sampling method works best when each neighborhood is very diverse. Because each neighborhood itself encompasses diversity, a cluster sample can reduce the time and cost associated with data collection, because the interviewer would need only go to some of the neighborhoods rather than to all parts of a city, in order to collect a useful sample. One-Stage Cluster Sampling Source: OpenIntro.Org Multistage Cluster Sampling A multistage or multistage cluster sampling is an extention of cluster sampling and involves two (or more) steps. First step is to take a cluster sample. Then, instead of including all of the individuals in these clusters in the sample, a second sampling method, usually SRS, is employed within each of the selected clusters. In the neighborhood example, we could first randomly select some number of neighborhoods and then take a SRS from just those selected neighborhoods. As seen in Figure, stratified sampling requires observations to be sampled from every stratum. Multistage sampling selects observations only from those clusters that were randomly selected in the first step. It is also possible to have more than two steps in multistage sampling. Each cluster may be naturally divided into subclusters. For example, each neighborhood could be divided into streets. To take a three-stage sample, we could first select some number of clusters (neighborhoods), and then, within the selected clusters, select some number of subclusters (streets). Finally, we could select some number of individuals from each of the selected streets. Source: OpenIntro.Org 2.4.4 Nonrandom Sampling Systematic Sampling Select every \\(k^{th}\\) individual froma list of the population, where the position of the first person chosen is randomly selected from the \\(k\\) individuals. This will give a non-representative sample if there is a structure to the list. Source: OpenIntro.Org Solve: The human resource department at a certain company wants to conduct a survey regarding worker benefits. The department has an alphabetical list of all \\(5465\\) employees at the company and wants to conduct a systematic sample of size \\(60\\). What is \\(k\\)? Determine the individuals who will be administered the survey. Randomly select a number from \\(1\\) to \\(k\\). Suppose that we randomly select \\(10\\). Starting with the first individual selected, the individuals in the survey will be Convenience or Volunteer Sampling Use the first \\(n\\) individuals that are available or the individuals who volunteer to participate. This is almost sure to give a non-representative sample which cannot be generalized to the population. Exercise: Identifying Sampling Methods A researcher randomly selects 20 Taco Bell locations and surveys all the employees at those locations. A news station hosts a call-in survey about whether physician-assisted death should be legalized in all states. A researcher randomly selects an LED TV out of the first 200 LED TVs on an assembly line and also selects every 200th LED TV after that. In a study at a community college, 30 instructors are randomly selected from fulltime instructors and 50 instructors are selected from part-time instructors. The City Hall of Spring Hill, Kansas, creates a frame of its 5730 residents and randomly selects 60 residents. Example: Non-Representative Sample Survey Surveyed 10 million people who were subcribers or had telephones. 2.4 million people responded (i.e. 24% response rate) Prediction Landslide victory of Landon. Election Result Landslide victory of Roosevelt. What did go wrong with the poll? Sample was drawn from telephone directories, club membership, magazine subscibers, etc. who were upper middle class people, largely excluding poor unemployed people. The sample suffered from both selection and nonresponse bias. 2.5 Sampling Errors Statistical Inference Inferential Statistics is the practice of using information from a sample to draw conclusions about the entire population. It is the process of making judgments about the parameters of a population and the reliability of statistical relationships, typically on the basis of random sampling. \\(\\require{AMScd}\\) \\[ \\begin{CD} Sample @&gt; {\\text {statistical inference}} &gt;&gt; Population \\end{CD} \\] \\[\\underbrace{\\text {sample statistics}}_{\\text{investigator knows}} = \\underbrace{\\text {population parameter}}_{\\text{investigator wants to know}} + \\underbrace{\\text {bias}}_{\\text{nonsampling error}} + \\underbrace{\\text {chance variation}}_{\\text{random sampling error}} \\] Random Sampling Error - occurs when the sample has been selected with a random method, but there is a discrepancy between a sample result and the true population result. Non-sampling Error - is the results of human error, including such factors as wrong data entries, computing errors, questions with biased wording, false data provided by respondents, forming biased conclusions, or applying statistical methods that are not appropriate for the circumstances. A sampling method that consistently underestimates or overestimates some characteristics of the population is said to be biased. Selection/Sampling bias - occurs when the sample is selected in such a way that it systematically excludes or underrepresented part of the population. An online survey conducted to estimate the percentage of Americans who have a Facebook account. The survey is biased because people who go online are favored. People who never go online cannot participate in the poll. Nonresponse bias - occurs when responses are not obtained from all individuals selected for inclusion in a sample. It happens if individuals refuse to be part of the study or if the research cannot track down individuals identified to be in the sample. Measurement or response bias - occurs when the data are collected in such a way that it tends to result in observed values that are different from the actual value in some systematic way. Contributing factors: question wording and order; mode of survey; influence of the interviewer; people might exaggerate how much money they earn; or a researcher might record the information incorrectly etc. Response bias can also result from the wording of questions. For example, compare the impact of the following two questions: Do you brag about your past successes with others? Do you inspire others by sharing your past successes? Do you share your past successes with others? Nonrandom Sampling Error - is the results of using a sampling method that is not random, such as using a convenience sample or a voluntary response sample. 2.6 Bias and Precision Bias The average difference between the estimator and the true value. Precision The standard deviation of the estimator. \\[ \\begin{aligned} \\text{Mean Squared Error, MSE} &amp;= precision^2 + bias^2 \\\\ \\text{Root Mean Squared Error, RMSE} &amp;= \\sqrt{MSE} \\end{aligned} \\] Statistical Studies Explanatory and Response Variables In statistical studies, we want to know whether a variable \\(x\\) explains (or affects) another variables \\(y\\). The \\(x\\) variable is called the explanatory or independent variable. The \\(y\\) variable is called the response or dependent variable. Association vs. Causation There is an association between an explanatory and response variable when the response variable changes as the explanatory variable changes. If the change in the explanatory variable causes the change in the response variable, then there is a causation between the variables. 2.7 Observational Studies Generally, data in observational studies are collected on specific characteristics only by passively monitoring study participants, but the observers dont attempt to modify the individuals being studied. These studies are inexpensive and good for discovering relationships related to rare outcomes. They are generally only sufficient to show associations. Types of observational studies: 1. Cross-sectional Studies - data are observed, measured, and collected at one point in time, not over a period of time. 2. Retrospective Studies - data are collected from a past time period by going back in time (through examinations of records, interviews, and so on). 3. Prospective (or longitudinal or cohort) Studies - data are collected in the future from groups that share common factors (such groups are called cohorts). Observational Study: drinking coffee and longevity Coffee drinkers may live longer - nytimes.com, May 16, 2012. Coffee may help you live longer, study suggests - thestar.com, May 17, 2012. No, drinking coffee probably wont make you live longer - washingtonpost.com, May 17, 2012. Association of coffee drinking with total and cause-specific mortality,\" New England Journal of Medicine, May 2012. Sample Size: 400,000 Age Range: 50-71 years Period: 1995 - 2008 Death: 52,000 How would you interpret the result? Confounding Variable A confounding variable is a variable that is associated with both the explanatory and response variables. Simultaneously with the explanatory variable, it may cause the response variable to change during the study. Because of the confounding variables association with both variables, we do not know if the response is due to the explanatory variable or due to the confounding variable. Sun exposure is a confounding factor because it is associated with both the use of sunscreen and the development of skin cancer. People who are out in the sun all day are more likely to use sunscreen, and people who are out in the sun all day are more likely to get skin cancer. Lurking Variable Lurking variables are variables that are not considered in the analysis, but may affect the nature of the relationship between the explanatory variable and the outcome. Table: 20-year survival status of women by smoking status \\[ \\begin{array}{c|lcr} &amp; \\text{Smoker} \\\\ &amp; \\text{Yes} &amp; \\text{No} \\\\ \\hline \\text {Dead} &amp; 0.239 &amp; 0.314 \\\\ \\text {Alive} &amp; 0.761 &amp; 0.686 \\end{array} \\] Are smokers less likely to die? 2.8 Experimental Design While observational studies are effective tools for answering certain research questions, experiments are essential to measure the effect of a treatment. In an experiment, we apply some treatment and then proceed to observe its effects on the individuals. Subject: Entity who is participating in the study. Treatment Group: The group of subjects that receives treatments. Control Group: The group of subjects that receives no treatment. Response Variable: The outcome of interest, measured on each subject. Factor: The categorical variable that explains the outcome of the experiment. Each category is called level. Blinding: When researchers keep the subjects uninformed about their treatment, the study is said to be blind. Its purpose is to reduce the potential for both researchers and subjects emotional bias. Subjects would not know which experimental group they are assigned to. The researcher (i.e. the person who is measuring the outcome) would not know which treatment is assigned to which experimental unit. Single-blind: only one type of blinding is applied. Double-blind: both types of blinding are applied. Placebo: A substance or treatment with no active ingredients. The control group receives the placebo treatment. This phenomenon, in which the recipient perceives an improvement in condition due to personal expectations, rather than the treatment itself, is known as the placebo effect. Principles of Experimental Design Well-conducted experiments are built on three main principles. Direct Control Researchers assign treatments to cases, and they do their best to control any other differences in the groups. They want the groups to be as identical as possible except for the treatment, so that at the end of the experiment any difference in response between the groups can be attributed to the treatment and not to some other confounding or lurking variable. Direct control refers to variables that the researcher can control. Randomization Researchers randomize patients into treatment groups to account for variables that cannot be controlled. Randomizing patients into the treatment or control group helps even out the effects of such differences, and it also prevents accidental bias from entering the study. Replication In a single study, replication is done by imposing the treatment on a sufficiently large number of subjects or experimental units. Scientists may also replicate the entire experiment on an entirely different population of experimental units to verify earlier findings. 2.8.1 Randomized Blocked Design Researchers sometimes know or suspect that another variable, other than the treatment, influences the response. Under these circumstances, they may carry out a blocked experiment. In this design, they first group individuals into blocks based on the identified variable (in other words, form blocks or groups of subjects with similar characteristics) and then randomize subjects within each block to the treatment groups. This strategy is referred to as blocking. For example, blocks can be designed based on gender or age group of subjects. 2.8.2 Completely Randomized Experimental Design A completely randomized experimental design is one in which the subjects or experimental units are randomly assigned to each group in the experiment. Source: OpenIntro.Org Case Study 1: PATRICIA Study | PApilloma TRIal against Cancer In young Adults The Lancet, Volume 374, Issue 9686, Pages 301 - 314, 25 July 2009 Efficacy of human papillomavirus (HPV) - 16/18 AS04-adjuvanted vaccine against cervical infection and precancer caused by oncogenic HPV types (PATRICIA); final analysis of a double-blind, randomized study in young women. Paavonen, et. al. \\[ \\begin{array}{c|c} {\\text{Response Variable} \\\\ \\text {(Acquired an infection)}} &amp; {\\text{Explanatory Variable} \\\\ \\text{(Given the HPV vaccine)}} \\\\ \\hline \\text{Yes} &amp; \\text{Yes} \\\\ \\text{No} &amp; \\text{No} \\\\ \\end{array} \\] \\[ \\bbox[yellow,5px] { \\color{black} { \\begin{array}{c} {\\text{Factor 1} \\\\ \\text{(2 Levels)}} \\\\ \\hline \\text{Drug A} \\\\ \\text{Drug B} \\end{array} } } \\] \\[ \\bbox[silver,5px] { \\color{black} { \\begin{array}{c} {\\text{Factor 2} \\\\ \\text{(2 Levels)}} \\\\ \\hline \\text{Dose A} \\\\ \\text{Dose B} \\end{array} } } \\] \\[ \\bbox[5px,border:2px solid red] { \\begin{array}{c} \\text{4 Treatments} \\\\ \\hline \\text{Drug A &amp; Dose A}\\\\ \\text{Drug A &amp; Dose B}\\\\ \\text{Drug B &amp; Dose A}\\\\ \\text{Drug B &amp; Dose B} \\end{array} } \\] Case Study 2: Ischemic Preconditioning | Effect on Muscular Endurance Can Ischemic Preconditioning improve athletic performance? Experimental units: 40 male teenagers Response Variable: length of time a wall squat position can be held Control Groups: 2 groups who received 0 lb pressure Control of Extraneous Factors: Age, sex, athletic ability Randomization: Randomly assigned 10 experimental units to each of 4 treatment groups \\[ \\bbox[yellow,5px] { \\color{black} { \\begin{array}{c|c} \\text{Factor1} &amp; {\\text{Amount of pressure} \\\\ \\text{applied by the} \\\\ \\text{bloodpressure cuff}} \\\\ \\hline \\text{Level 1} &amp; \\text{20 lb} \\\\ \\text{Level 2} &amp; \\text{0 lb} \\\\ \\end{array} } } \\] \\[ \\bbox[silver,5px] { \\color{black} { \\begin{array}{c|c} \\text{Factor2} &amp; {\\text{Length of time pressure} \\\\ \\text{was applied}} \\\\ \\hline \\text{Level 1} &amp; \\text{10 min} \\\\ \\text{Level 2} &amp; \\text{20 min} \\\\ \\end{array} } } \\] \\[ \\bbox[5px,border:2px solid red] { \\begin{array}{c} \\text{4 Treatments} \\\\ \\hline \\text{20 lb/10 min}\\\\ \\text{20 lb/20 min}\\\\ \\text{0 lb/ 10 min}\\\\ \\text{0 lb/ 20 min} \\end{array} } \\] Components of a Well-Designed Study There should be a control group and at least one treatment group. Individuals should be randomly assigned to the control and treatment group(s). The sample size should be large enough. A placebo should be used when appropriate. The study should be double-blind when possible. If this is impossible, then the study should be single-blind if possible. Practice: Identifying an Experiment and an Observational Study Identify whether the study is an experiment or an observational study. Discuss whether the components of a good study were used. For five years, the author taught an innovative intermediate algebra course in which students learned by working in groups. Then the author compared the proportion of his successful intermediate algebra students who passed trigonometry with the proportion of other professors successful intermediate algebra students who passed trigonometry. Practice: Redesign an Observational Study into a Well-Designed Experiment A researcher wants to determine whether taking vitamin C helps people avoid getting the flu and the common cold. She randomly selects 100 people and asks them whether they take vitamin C and how often they had the flu or a cold in the past year. The researcher analyzes the responses and concludes that vitamin C helps people avoid the flu and colds. Describe some problems with the observational study. Include in your description at least one possible lurking or confounding variable and identify which type it is. Redesign the study so that it is a well-designed experiment. "],["exploring-data-with-tables-and-graphs.html", "Chapter 3 Exploring Data with Tables and Graphs 3.1 Frequency Distribution 3.2 Histogram 3.3 Other Charts", " Chapter 3 Exploring Data with Tables and Graphs Learning Outcome: Interpret quantitative data using tables and graphs, and descriptive statistics using histograms. The chapter introduces various techniques such as frequency table and histogram to organize quantitative data to explore its important characteristics. 3.1 Frequency Distribution \\(\\text {Table: Drive-Through Service Times (seconds) for McDonald&#39;s Lunches}\\) A frequency distribution (or frequency table) shows how data are partitioned among several categories (or classes) by listing the categories along with the number (frequency) of data values in each of them. \\[ \\bbox[white,4px] { \\color{black} { \\begin{array}{c|c|c|c} \\text{Time(Seconds)} &amp; \\text{Frequency} \\\\ \\hline \\text{75-124} &amp; \\text{11} \\\\ \\text{125-174} &amp; \\text{24} \\\\ \\text{175-224} &amp; \\text{10} \\\\ \\text{225-274} &amp; \\text{3} \\\\ \\text{275-324} &amp; \\text{2} \\\\ \\hline \\text{Total} &amp; 50 \\end{array} } } \\] Lower class limits: \\({75, 125, 175, 225, 275}\\) Upper class limits: \\({124, 174, 224, 274, 324}\\) Class boundaries: \\({74.5, 124,5, 174.5, 224.5, 274.5, 324.5}\\) Class midpoints: \\({99.5, 149.5, 199.5, 249.5, 299.5}\\) Class width: \\(124.5 - 74.5 = 50\\) Relative Frequency Distribution A relative frequency distribution (or percentage frequency distribution) is a variation of the basic frequency distribution in which a class frequency is replaced by a relative frequency (or proportion). \\[ \\begin{align} \\text{relative frequency for a class} &amp;= \\dfrac{\\text{frequency for a class}}{\\text{sum of all frequencies}} \\\\ \\text{percentage of a class} &amp;= \\dfrac{\\text{frequency for a class}}{\\text{sum of all frequencies}} \\times 100\\%\\\\ \\end{align} \\] \\[ \\bbox[white,4px] { \\color{black} { \\begin{array}{c|c} \\text{Time(Seconds)} &amp; \\text{Relative Frequency} \\\\ \\hline \\text{75-124} &amp; \\text{22}\\% \\\\ \\text{125-174} &amp; \\text{48}\\% \\\\ \\text{175-224} &amp; \\text{20}\\% \\\\ \\text{225-274} &amp; \\text{6}\\% \\\\ \\text{275-324} &amp; \\text{4}\\% \\\\ \\hline &amp; 100\\% \\end{array} } } \\] Cumulative Distribution \\[ \\bbox[white,4px] { \\color{black} { \\begin{array}{c|c|c} \\text{Time(Seconds)} &amp; \\text{N} &amp; \\text{%} \\\\ \\hline \\text{75-124} &amp; 11 &amp; \\text{22}\\% \\\\ \\text{125-174} &amp; 35 &amp; \\text{70}\\% \\\\ \\text{175-224} &amp; 45 &amp; \\text{90}\\% \\\\ \\text{225-274} &amp; 48 &amp; \\text{96}\\% \\\\ \\text{275-324} &amp; 50 &amp; \\text{100}\\% \\\\ \\hline \\end{array} } } \\] 3.2 Histogram A histogram is a graph consisting of bars of equal width drawn adjacent to each other. The horizontal scale represents classes of quantitative data values; and the vertical scale represents frequencies. A relative frequency histogram has the same shape and horizontal scale as a histogram, but the vertical scale uses relative frequencies (as percentages) instead of actual frequencies. Importance of Histogram Visually displays the shape of the distribution of the data Shows the location of the center of the data Shows the spread of the data Identifies outliers Density Histogram \\[ \\begin{align} \\textbf{Density} &amp;= \\dfrac{\\textbf{relative frequency}}{\\textbf{bin width}} \\\\ \\text {Density of class (75-124)} &amp;= \\dfrac{\\text{rel. freq of class (75-124)}}{\\text{class width}} \\\\ &amp;= \\dfrac{0.22}{50} \\\\ &amp;= 0.0044 \\end{align} \\] In density histogram, area of each rectangular bar is the relative frequency of its class. Practice - Construct a Density Histogram The accompanying frequency distribution summarizes data on the number of times smokers attempted to quit before their final successful attempts. \\[ \\bbox[yellow,5px] { \\color{black} { \\begin{array}{r|c} \\text{Number of attempts} &amp; \\text{Frequency} \\\\ \\hline \\textbf{0-10} &amp; 778 \\\\ \\textbf{10-20} &amp; 306 \\\\ \\textbf{20-30} &amp; 274 \\\\ \\textbf{30-40} &amp; 221 \\\\ \\textbf{40-50} &amp; 238 \\end{array} } } \\] 3.3 Other Charts Dotplot A dotplot uses dots to show the frequency, or number of occurrences, of the values in a data set. The higher the stack of dots, the greater the number of occurrences there are of the corresponding value. Pie Charts The distribution of a categorical variable can be described by a pie chart, which is a disk where slices represent the categories. The proportion of the total area for one slice is equal to the relative frequency for the category represented by the slice. The relative frequencies are usually written as percentages. Example 1: Construct and Interpret a Pie Chart A total of 273 children were surveyed about what job they would want to do. The jobs and the percentages of the children who voted for them are shown in the table. \\[ \\bbox[yellow,5px] { \\color{black} { \\begin{array}{r|c} \\text{Job} &amp; \\text{Percent} \\\\ \\hline \\text{Spy/Agent} &amp; 16 \\\\ \\text{Veterinarian} &amp; 13 \\\\ \\text{Professional Athlete} &amp; 12 \\\\ \\text{Movie Star} &amp; 10 \\\\ \\text{Video Game Designer} &amp; 8 \\\\ \\text{Doctor} &amp; 6 \\\\ \\text{Other} &amp; 35 \\end{array} } } \\] Questions: Find the proportion of the observations that fall in the spy category. Find the proportion of the observations that do NOT fall in the spy category. Find the proportion of the observations that fall in the athlete category OR fall in the movie-star category. Interpreting a Multiple Bar Graph In a survey in 2012, 1960 adults were asked the following question: Generally speaking, do you usually think of yourself as a Republican, Democrat, Independent, or other? The results of the survey are described by the multiple bar graph. What proportion of women thought of themselves as Democrats? Which political party did the greatest proportion of men choose? Compare the proportion of women who thought of themselves as Independents to the proportion of men who thought of themselves as Independents. A total of 1081 women and 879 men responded to the survey. Were there more women or men who thought of themselves as Independents? How is this possible, given there was a smaller proportion of women who thought of themselves as Independents than men? Two-Way (Contingency) Table The table summarizes the responses from all 42 students who participated in the survey about whether they had read a novel in the past year. \\[ \\bbox[yellow,5px] { \\color{black} { \\begin{array}{l|c|c|c} \\text{Gender} &amp; \\text{Did Not Read Novel} &amp; \\text{Read Novel} &amp; \\text{Total} \\\\ \\hline \\text{Female} &amp; 6 &amp; 19 &amp; 25 \\\\ \\text{Male} &amp; 6 &amp; 11 &amp; 17 \\\\ \\hline \\text{Total} &amp; 12 &amp; 30 &amp; 42 \\\\ \\hline \\end{array} } } \\] How many of the students read a novel in the past year? What proportion of the students did not read a novel in the past year? What proportion of the women read a novel in the past year? What proportion of the students is men AND read a novel in the past year? "],["describing-exploring-and-comparing-data.html", "Chapter 4 Describing, Exploring, and Comparing Data 4.1 Measures of Shape 4.2 Measures of Center 4.3 Measures of Spread or Variation 4.4 Normal Distribution and Standard Deviation 4.5 Percentiles and Quartiles 4.6 Boxplot 4.7 Group Comparison", " Chapter 4 Describing, Exploring, and Comparing Data Learning Outcome: Calculate measures of central tendency, position, and spread, including standard deviation. Interpret quantitative data using graphs and descriptive statistics with emphasis on histograms and boxplots. In this chapter, we will numerically describe distributions of quantitative variables. Distributions, such as histograms, can be described by three characteristics: shape, center, and spread. 4.1 Measures of Shape Modes The mode of some data is an observation with the greatest frequency. There can be more than one mode, but if all the observations have frequency 1, then there is no mode. Mode is represented by a prominent peak in the distribution. Unimodel Distribution Bimodal Distribution Multimodal Distribution Uniform Distribution All the bins have the same frequency, or at least close to the same frequency. It is a distribution without a mode. Symmetry The histogram for a symmetric distribution will look the same on the left and the right of its center. Skew A histogram is skewed right if the longer tail is on the right side of the mode. A histogram is skewed left if the longer tail is on the left side of the mode. Outlier An Outlier is a data value that is far above or far below the rest of the data values. 4.2 Measures of Center Mean The sample mean of a numerical variable is computed as the sum of all of the observations \\(\\{x_1, x_2, \\cdots, x_n\\}\\) divided by the number of observations \\((n)\\). If \\(\\bar x\\) is the mean, then \\[ \\displaystyle (\\bar x - x_1) + (\\bar x - x_2) + \\cdots + (\\bar x - x_n) = 0 \\\\ \\displaystyle \\text{Therefore}, \\ \\bar x = \\frac{(x_1+x_2+...+x_n)}{n} = \\dfrac{1}{n}\\sum_{i=1}^n x_i \\] The mean follows the tail In a right skewed distribution, the mean is greater than the median. In a left skewed distribution, the mean is less than the median. In a symmetric distribution, the mean and median are approximately equal. Median The median splits an ordered data set in half. If there are an even number of observations, the median is the average of the two middle values. If there are an odd number of observations, the median is the middle value. 0 0 0 0 0 0 1 1 1 1 1 2 2 3 3 3 4 4 5 5 5 6 6 7 7 7 9 9 9 10 10 10 11 11 12 14 14 16 17 22 25 25 25 26 26 27 29 42 43 64 Calculating the Median \\(n\\) is odd Sort the series in ascending order. If the series has odd number \\((n)\\) of entries, the median is at position \\(\\frac{n+1}{2}.\\) Find the median of the series: \\(2,4,5,(6),7,9,9\\) The median is \\(6.\\) \\(n\\) is even Sort the series in ascending order. If the series has even number \\((n)\\) of entries, the median is the average of the two middle numbers: \\(\\frac{n}{2},\\frac{n+1}{2}.\\) Find the median of the numbers: \\(2,2,4,6,7,8\\) Median is the average of the third and the fourth numbers: \\(\\frac{4+6}{2}=5\\) Example: Comparing the Medians of Two Distributions \\[ \\begin{array}{lclc} \\text{Pacific State} &amp; \\text{Minimum Wage} &amp; \\text{Mountain State} &amp; \\text{Minimum Wage} \\\\ \\hline \\text {Alaska} &amp; 7.75 &amp; \\text {Arizona} &amp; 7.90 \\\\ \\text {California} &amp; 8.00 &amp; \\text {Colorado} &amp; 8.00 \\\\ \\text {Hawaii} &amp; 7.25 &amp; \\text {Idaho} &amp; 7.25 \\\\ \\text {Oregon} &amp; 9.10 &amp; \\text {Montana} &amp; 7.90 \\\\ \\text {Washington} &amp; 9.32 &amp; \\text {Nevada} &amp; 8.25 \\\\ &amp; &amp; \\text {New Mexico} &amp; 7.50 \\\\ &amp; &amp; \\text {Utah} &amp; 7.25 \\\\ &amp; &amp; \\text {Wyoming} &amp; 5.15 \\\\ \\end{array} \\] Find the median minimum wages of the Pacific and Mountain states. How the Shape of a Distribution Affects the Mean and the Median If a distribution is skewed left, the mean is usually less than the median and the median is usually a better measure of the center. If a distribution is symmetric, the mean is approximately equal to the median and both are reasonable measures of the center. If a distribution is skewed right, the mean is usually greater than the median and the median is usually a better measure of the center. List: \\({2,3,3,4}\\) List: \\(2,3,3,7\\) \\(\\textbf {Notice: The median is unaffected by outliers.}\\) Weighted Mean The weighted mean is the same as the mean, except that it is influenced more by some observations than others. We assign weights to observations as a sort of way of describing its relative importance. The weighted mean of observations \\(x_1, x_2,...,x_n\\) using weights \\(w_1, w_2,...,w_n\\) is given by \\(\\displaystyle \\bar x =\\frac{w_1x_1+w_2x_2+...+w_nx_n}{w_1+w_2+...+w_n}\\) The simple mean is a weighted mean where all the weights are 1. \\(\\displaystyle \\bar x =\\frac{1\\times x_1+1\\times x_2+...+1\\times x_n}{1+1+...+1} = \\frac{x_1+x_2+...+x_n}{n}\\) Calculating Mean from a Frequency Distribution \\[ \\bar x = \\dfrac{\\sum (f \\cdot x)}{\\sum f} \\] where, \\(f\\) is the class frequency and \\(x\\) is the class midpoint. \\[ \\bbox[white,4px] { \\color{black} { \\begin{array}{c|c|c|c} \\text{Time(Seconds)} &amp; \\text{Frequency } f &amp; \\text{Class Midpoint } x &amp; f \\cdot x \\\\ \\hline \\text{75-124} &amp; 11 &amp; 99.5 &amp; 1094.5 \\\\ \\text{125-174} &amp; 24 &amp; 149.5 &amp; 3588.0 \\\\ \\text{175-224} &amp; 10 &amp; 199.5 &amp; 1995.0 \\\\ \\text{225-274} &amp; 3 &amp; 249.5 &amp; 748.5 \\\\ \\text{275-324} &amp; 2 &amp; 299.5 &amp; 599.0 \\\\ \\hline \\text{Total} &amp; \\sum f = 50 &amp; &amp; \\sum(f \\cdot x) = 8025.0 \\\\ \\end{array} } } \\] \\[ \\displaystyle \\bar x = \\dfrac{\\sum (f \\cdot x)}{\\sum f} = \\dfrac{8025.0}{50} = 160.5 \\] Midrange The midrange of a data set is the measure of center that is the value midway between the maximum and minimum values in the original data set. It is found by adding the maximum data value to the minimum data value and then dividing the sum by \\(2\\), as the following formula: \\[ \\text {Midrange} = \\dfrac{\\text{maximum data value + minimum data value}}{2} \\] 4.3 Measures of Spread or Variation Range The range of a set of data is the difference between the maximum and the minimum data values. \\(\\textbf {range = maximum - minimum}\\) The range is sensitive to outliers. A single high or low value will affect the range significantly. Standard Deviation of a Sample SD \\((s)\\) of a set of sample values is a measure of how much, on average, the data values deviate away from the sample mean. In other word, SD describes the variability of the data set within the range of the dataset. Low variability or small spread means that the values tend to be more clustered together. High variability or large spread means that the values tend to be far apart. Calculating the Standard Deviation The standard deviation is the square root of the variance. It is roughly the average distance of the observations from the mean. \\[ \\bbox[yellow,5px] { \\color{black}{s= \\sqrt{\\frac{1}{n-1}\\sum(x_i-\\bar x)^2}} } \\] Exercise: \\(1. Calculate \\space SD \\space of \\space [0,1]\\) \\(2. Calculate \\space SD \\space of \\space [30,20, 41, 21]\\) Which histogram has the largest SD? Hint: pay attention to the range of the distributions. Calculating Standard Deviation from a Frequency Distribution \\(\\text {Step 1: Calculate weighted average from the class midpoint and class frequency}\\) \\[ \\bar x = \\dfrac{\\sum (f \\cdot x)}{\\sum f} \\] where, \\(f\\) is the class frequency and \\(x\\) is the class midpoint. \\[ \\bbox[white,4px] { \\color{black} { \\begin{array}{c|c|c|c} \\text{Time(Seconds)} &amp; \\text{Frequency } f &amp; \\text{Class Midpoint } x &amp; f \\cdot x \\\\ \\hline \\text{75-124} &amp; 11 &amp; 99.5 &amp; 1094.5 \\\\ \\text{125-174} &amp; 24 &amp; 149.5 &amp; 3588.0 \\\\ \\text{175-224} &amp; 10 &amp; 199.5 &amp; 1995.0 \\\\ \\text{225-274} &amp; 3 &amp; 249.5 &amp; 748.5 \\\\ \\text{275-324} &amp; 2 &amp; 299.5 &amp; 599.0 \\\\ \\hline \\text{Total} &amp; \\sum f = 50 &amp; &amp; \\sum(f \\cdot x) = 8025.0 \\\\ \\end{array} } } \\] \\[ \\displaystyle \\bar x = \\dfrac{\\sum (f \\cdot x)}{\\sum f} = \\dfrac{8025.0}{50} = 160.5 \\] \\(\\text {Step 2: Calculate variance}\\) \\[ \\displaystyle s^2 = \\dfrac{1}{\\sum_{i} f_i - 1}\\sum_{i} f_i(x_i - \\bar x)^2 \\] \\[ \\bbox[white,4px] { \\color{black} { \\begin{array}{c|c|c|c} \\text{Time(Seconds)} &amp; \\text{Frequency } f &amp; \\text{Class Midpoint } x &amp; f_i(x_i - \\bar x)^2 \\\\ \\hline \\text{75-124} &amp; 11 &amp; 99.5 &amp; 40931 \\\\ \\text{125-174} &amp; 24 &amp; 149.5 &amp; 2904 \\\\ \\text{175-224} &amp; 10 &amp; 199.5 &amp; 15210 \\\\ \\text{225-274} &amp; 3 &amp; 249.5 &amp; 23763 \\\\ \\text{275-324} &amp; 2 &amp; 299.5 &amp; 38642 \\\\ \\hline \\text{Total} &amp; \\sum f = 50 &amp; &amp; \\sum f_i(x_i - \\bar x)^2 = 121450 \\\\ \\end{array} } } \\] \\[ \\begin{align} s^2 &amp;= \\dfrac{121450}{50-1} = 2478.6 \\\\ \\end{align} \\] \\(\\text {Step 3: Calculate standard deviation}\\) \\[ \\begin{align} s &amp;= \\sqrt {2478.6} = 49.8 \\end{align} \\] Standard Deviation of a Population \\[ \\bbox[yellow,5px] { \\color{black}{\\sigma= \\sqrt{\\frac{1}{N}\\sum(x_i-\\mu)^2}} } \\] Variance of a Sample and Population The variance of a set of values is a measure of variation equal to the square of the standard variation. Sample variance: \\(s^2 =\\) square of the sample standard deviation \\(s\\). Population variance: \\(\\sigma^2 =\\) square of the population standard deviation \\(\\sigma\\). Why is \\((n-1)\\) used to calculate standard deviation? \\(s` = \\sqrt{\\frac{1}{n}\\sum(x_i-\\bar x)^2}\\) is not an unbiased estimator of the population standard deviation \\(\\sigma\\), meaning that the distribution of \\(s\\) does not tend to center around \\(\\sigma\\). Therefore, an adjustment is applied by replacing \\(n\\) by \\((n-1)\\) in the denominator. \\(s = \\sqrt{\\frac{1}{n-1}\\sum(x_i-\\bar x)^2}\\) is an unbiased estimator of \\(\\sigma\\). Also, with division by \\(n-1\\), sample variance \\(s^2\\) tend to center around the value of the population variance \\(\\sigma^2\\); with division by \\(n\\), sample variances \\(s^2\\) tend to underestimate the value of the population variance \\(\\sigma^2\\). Coefficient of Variation The coefficient of variation (CV) for a set of non-negative sample or population data, expressed as a percent, describes the standard deviation relative to the mean, and is given by the following: \\[ Sample: CV = \\frac{s}{x}.100 \\\\ Population: CV = \\frac{\\sigma}{x}.100 \\] 4.4 Normal Distribution and Standard Deviation Probabilities for falling 1, 2, and 3 standard deviations of the mean in a normal distribution. Empirical Rule of Normal Distribution \\[ \\begin{array}{lc} \\text{Interval} &amp; \\text{Percent} \\\\ \\hline \\mu \\pm \\sigma &amp; 68 \\% \\\\ \\mu \\pm 2\\sigma &amp; 95 \\% \\\\ \\mu \\pm 3\\sigma &amp; 99.7 \\% \\\\ \\hline \\end{array} \\] z-score A z-score (or standard score or standardized value) is the number of standard deviations that a given value \\(x\\) is above or below the mean. The \\(z\\) score is calculated by using one of the following: \\[z= \\dfrac{x-\\bar x}{s}\\] Example: The \\(4000\\) g weight of a newborn baby (among 400 weighs with sample mean \\(\\bar x = 3152.0\\) g and sample standard deviation \\(s = 693.4\\) g) \\[ z = \\dfrac{x - \\bar x}{s} = \\dfrac{4000 - 3152.0}{693.4} = 1.22 \\] The weight \\(4000\\) g is \\(1.22\\) standard deviations away from the mean. 4.5 Percentiles and Quartiles Percentiles are measures of location, denoted \\(P_1, P_2, \\cdots, P_{99}\\), which divide a set of data into \\(100\\) groups with about \\(1\\%\\) of the values in each group. Example - the \\(50\\)th percentile, denoted \\(P_{50}\\) has about \\(50\\%\\) of the data values below it and about \\(50\\%\\) of the data value above it. The \\(n^{th}\\) percentile is the data value such that \\(n\\) percent of the data lies below that value and \\((100-n)\\) percent of the data falls above that value. \\[ \\text{Percentile of value } x = \\frac{\\text{number of values less than } x}{\\text{total number of values}} \\times 100 \\] Finding a Percentile \\(\\text {Table: Data Speeds (mbps) at Various Airports}\\) Find the percentile for the data of 11.8 mbps. There are \\(50\\) data speeds in the table. There are \\(20\\) data speeds less than \\(11.8\\) mbps. \\(\\therefore\\) percentile of \\(11.8 = \\dfrac{20}{50} \\cdot 100 = 40\\) Interpretation: A data speed of \\(11.8\\) mbps is in the \\(40\\)th percentile. This means \\(40\\%\\) of the airports reported data speeds less than \\(11.8\\) mbps. Find the 40th percentile. First, compute the locator, \\(L = \\dfrac{k}{100} \\cdot n = \\dfrac{40}{100} \\cdot 50 = 20.\\) By definition, \\(P_{40}\\) below which \\(40\\%\\) of the data points fall. Hence, the \\(40\\)th percentile is midway between the \\(20\\)th and \\(21\\)st value. In the table above, \\(20th\\) value is \\(11.6\\) and \\(21\\)st value is \\(11.8\\), so the midway between them is \\(11.7\\) mbps. \\(\\therefore P_{40} = 11.7\\) mbps. Find the 25th percentile. \\(L = \\dfrac{k}{100} \\cdot n = \\dfrac{25}{100} \\cdot 50 = 12.5.\\) In this case, we round up the value of \\(L\\) to get \\(13\\) to make sure at least \\(12.5\\%\\) data points fall below that point. \\(\\therefore P_{25} = 7.9\\) mbps. Three Quartiles \\((Q_1, Q_2, Q_3)\\) \\(Q_1\\) represents the first quartile, which is the 25th percentile, and is the median of the smaller half of the data set. \\(Q_2\\) represents the second quartile, which is equivalent to the 50th percentile (i.e. the median). \\(Q_3\\) represents the third quartile, or 75th percentile, and is the median of the larger half of the data set Interquartile Range \\((IQR) = Q_3 - Q_1\\) 4.6 Boxplot 5-Number Summary For a set of data, the 5-number summary consists of five values: minimum first quartile, \\(Q_1\\) second quartile (median), \\(Q_2\\) third quartile, \\(Q_3\\) Maximum A boxplot (or box-and-whisker diagram) is a graph of a data set that consists of a line extending from the minimum value to the maximum value, and a box with lines drawn at the first quartile \\((Q_1)\\), the median \\((Q_2)\\), and the third quartile \\((Q_3)\\). Outlier and Fences When in the context of a box plot, define an outlier as an observation that right fence: \\[ &gt; Q_3 + 1.5 \\times IQR \\] left fence: \\[ &lt; Q_1 - 1.5 \\times IQR \\] Such points are marked using a dot or asterisk in a box plot. Example: Data: \\([5, 5, 9, 10, 15, 16, 20, 30, 40]\\) Five Number Summary: Min. 1st Qu. Median Mean 3rd Qu. Max. 5.00 9.00 15.00 16.67 20.00 40.00 Exercise: Drawing a Boxplot with an Outlier Students in one of the authors statistics classes were surveyed about the number of novels they read in the past year. Here are the anonymous responses (in numbers of novels) of 11 of the students: \\([2, 5, 2, 0, 2, 3, 0, 5, 6, 4, 12]\\) Construct a boxplot. Check if there is any outlier. 4.7 Group Comparison Comparing distributions of median household income for counties by population gain status Source: OpenIntroOrg "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
