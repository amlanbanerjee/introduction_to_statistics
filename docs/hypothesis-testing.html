<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 8 Hypothesis Testing | Introduction to Statistics</title>
  <meta name="description" content="Chapter 8 Hypothesis Testing | Introduction to Statistics" />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 8 Hypothesis Testing | Introduction to Statistics" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 8 Hypothesis Testing | Introduction to Statistics" />
  
  
  

<meta name="author" content="Amlan Banerjee, Ph.D." />


<meta name="date" content="2022-02-15" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="estimating-parameters-and-determining-sample-sizes.html"/>

<script src="libs/header-attrs-2.11/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>
<script src="libs/htmlwidgets-1.5.4/htmlwidgets.js"></script>
<script src="libs/plotly-binding-4.10.0/plotly.js"></script>
<script src="libs/typedarray-0.1/typedarray.min.js"></script>
<link href="libs/crosstalk-1.2.0/css/crosstalk.min.css" rel="stylesheet" />
<script src="libs/crosstalk-1.2.0/js/crosstalk.min.js"></script>
<link href="libs/plotly-htmlwidgets-css-2.5.1/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotly-main-2.5.1/plotly-latest.min.js"></script>




<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Introduction to Statistics</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Course Information</a>
<ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#course-description"><i class="fa fa-check"></i><b>1.1</b> Course Description</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#course-outcomes"><i class="fa fa-check"></i><b>1.2</b> Course Outcomes</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>2</b> Introduction</a>
<ul>
<li class="chapter" data-level="2.1" data-path="introduction.html"><a href="introduction.html#what-is-statistics"><i class="fa fa-check"></i><b>2.1</b> What is Statistics?</a></li>
<li class="chapter" data-level="2.2" data-path="introduction.html"><a href="introduction.html#statistical-thinking"><i class="fa fa-check"></i><b>2.2</b> Statistical Thinking</a></li>
<li class="chapter" data-level="2.3" data-path="introduction.html"><a href="introduction.html#types-of-data-or-variable"><i class="fa fa-check"></i><b>2.3</b> Types of Data or Variable</a></li>
<li class="chapter" data-level="2.4" data-path="introduction.html"><a href="introduction.html#sampling-methods"><i class="fa fa-check"></i><b>2.4</b> Sampling Methods</a>
<ul>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html#sampling-from-a-population"><i class="fa fa-check"></i>Sampling from a Population</a></li>
<li class="chapter" data-level="2.4.1" data-path="introduction.html"><a href="introduction.html#simple-random-sampling-srs"><i class="fa fa-check"></i><b>2.4.1</b> Simple Random Sampling (SRS)</a></li>
<li class="chapter" data-level="2.4.2" data-path="introduction.html"><a href="introduction.html#stratified-sampling"><i class="fa fa-check"></i><b>2.4.2</b> Stratified Sampling</a></li>
<li class="chapter" data-level="2.4.3" data-path="introduction.html"><a href="introduction.html#cluster-sampling"><i class="fa fa-check"></i><b>2.4.3</b> Cluster Sampling</a></li>
<li class="chapter" data-level="2.4.4" data-path="introduction.html"><a href="introduction.html#nonrandom-sampling"><i class="fa fa-check"></i><b>2.4.4</b> Nonrandom Sampling</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="introduction.html"><a href="introduction.html#sampling-errors"><i class="fa fa-check"></i><b>2.5</b> Sampling Errors</a></li>
<li class="chapter" data-level="2.6" data-path="introduction.html"><a href="introduction.html#bias-and-precision"><i class="fa fa-check"></i><b>2.6</b> Bias and Precision</a>
<ul>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html#statistical-studies"><i class="fa fa-check"></i>Statistical Studies</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="introduction.html"><a href="introduction.html#observational-studies"><i class="fa fa-check"></i><b>2.7</b> Observational Studies</a></li>
<li class="chapter" data-level="2.8" data-path="introduction.html"><a href="introduction.html#experimental-design"><i class="fa fa-check"></i><b>2.8</b> Experimental Design</a>
<ul>
<li class="chapter" data-level="2.8.1" data-path="introduction.html"><a href="introduction.html#randomized-blocked-design"><i class="fa fa-check"></i><b>2.8.1</b> Randomized Blocked Design</a></li>
<li class="chapter" data-level="2.8.2" data-path="introduction.html"><a href="introduction.html#completely-randomized-experimental-design"><i class="fa fa-check"></i><b>2.8.2</b> Completely Randomized Experimental Design</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="exploring-data-with-tables-and-graphs.html"><a href="exploring-data-with-tables-and-graphs.html"><i class="fa fa-check"></i><b>3</b> Exploring Data with Tables and Graphs</a>
<ul>
<li class="chapter" data-level="3.1" data-path="exploring-data-with-tables-and-graphs.html"><a href="exploring-data-with-tables-and-graphs.html#frequency-distribution"><i class="fa fa-check"></i><b>3.1</b> Frequency Distribution</a></li>
<li class="chapter" data-level="3.2" data-path="exploring-data-with-tables-and-graphs.html"><a href="exploring-data-with-tables-and-graphs.html#histogram"><i class="fa fa-check"></i><b>3.2</b> Histogram</a></li>
<li class="chapter" data-level="3.3" data-path="exploring-data-with-tables-and-graphs.html"><a href="exploring-data-with-tables-and-graphs.html#other-charts"><i class="fa fa-check"></i><b>3.3</b> Other Charts</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="describing-exploring-and-comparing-data.html"><a href="describing-exploring-and-comparing-data.html"><i class="fa fa-check"></i><b>4</b> Describing, Exploring, and Comparing Data</a>
<ul>
<li class="chapter" data-level="4.1" data-path="describing-exploring-and-comparing-data.html"><a href="describing-exploring-and-comparing-data.html#measures-of-shape"><i class="fa fa-check"></i><b>4.1</b> Measures of Shape</a></li>
<li class="chapter" data-level="4.2" data-path="describing-exploring-and-comparing-data.html"><a href="describing-exploring-and-comparing-data.html#measures-of-center"><i class="fa fa-check"></i><b>4.2</b> Measures of Center</a></li>
<li class="chapter" data-level="4.3" data-path="describing-exploring-and-comparing-data.html"><a href="describing-exploring-and-comparing-data.html#measures-of-spread-or-variation"><i class="fa fa-check"></i><b>4.3</b> Measures of Spread or Variation</a></li>
<li class="chapter" data-level="4.4" data-path="describing-exploring-and-comparing-data.html"><a href="describing-exploring-and-comparing-data.html#normal-distribution-and-standard-deviation"><i class="fa fa-check"></i><b>4.4</b> Normal Distribution and Standard Deviation</a>
<ul>
<li class="chapter" data-level="" data-path="describing-exploring-and-comparing-data.html"><a href="describing-exploring-and-comparing-data.html#z-score"><i class="fa fa-check"></i>z-score</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="describing-exploring-and-comparing-data.html"><a href="describing-exploring-and-comparing-data.html#percentiles-and-quartiles"><i class="fa fa-check"></i><b>4.5</b> Percentiles and Quartiles</a></li>
<li class="chapter" data-level="4.6" data-path="describing-exploring-and-comparing-data.html"><a href="describing-exploring-and-comparing-data.html#boxplot"><i class="fa fa-check"></i><b>4.6</b> Boxplot</a></li>
<li class="chapter" data-level="4.7" data-path="describing-exploring-and-comparing-data.html"><a href="describing-exploring-and-comparing-data.html#group-comparison"><i class="fa fa-check"></i><b>4.7</b> Group Comparison</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="discrete-probability-distributions.html"><a href="discrete-probability-distributions.html"><i class="fa fa-check"></i><b>5</b> Discrete Probability Distributions</a>
<ul>
<li class="chapter" data-level="5.1" data-path="discrete-probability-distributions.html"><a href="discrete-probability-distributions.html#definitions-1"><i class="fa fa-check"></i><b>5.1</b> Definitions</a></li>
<li class="chapter" data-level="5.2" data-path="discrete-probability-distributions.html"><a href="discrete-probability-distributions.html#finding-probabilities"><i class="fa fa-check"></i><b>5.2</b> Finding Probabilities</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="discrete-probability-distributions.html"><a href="discrete-probability-distributions.html#disjoint-or-mutually-exclusive-outcomes"><i class="fa fa-check"></i><b>5.2.1</b> Disjoint or mutually exclusive outcomes</a></li>
<li class="chapter" data-level="5.2.2" data-path="discrete-probability-distributions.html"><a href="discrete-probability-distributions.html#probabilities-when-events-are-not-disjoint-or-mutually-exclusive"><i class="fa fa-check"></i><b>5.2.2</b> Probabilities when events are NOT disjoint or mutually exclusive</a></li>
<li class="chapter" data-level="5.2.3" data-path="discrete-probability-distributions.html"><a href="discrete-probability-distributions.html#complement-of-an-event"><i class="fa fa-check"></i><b>5.2.3</b> Complement of an event</a></li>
<li class="chapter" data-level="5.2.4" data-path="discrete-probability-distributions.html"><a href="discrete-probability-distributions.html#multiplication-rule-for-independent-processes"><i class="fa fa-check"></i><b>5.2.4</b> Multiplication Rule | for independent processes</a></li>
<li class="chapter" data-level="5.2.5" data-path="discrete-probability-distributions.html"><a href="discrete-probability-distributions.html#marginal-and-joint-probabilities"><i class="fa fa-check"></i><b>5.2.5</b> Marginal and joint probabilities</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="discrete-probability-distributions.html"><a href="discrete-probability-distributions.html#probability-distributions"><i class="fa fa-check"></i><b>5.3</b> Probability Distributions</a></li>
<li class="chapter" data-level="5.4" data-path="discrete-probability-distributions.html"><a href="discrete-probability-distributions.html#parameters-of-a-probability-distribution"><i class="fa fa-check"></i><b>5.4</b> Parameters of a Probability Distribution</a></li>
<li class="chapter" data-level="5.5" data-path="discrete-probability-distributions.html"><a href="discrete-probability-distributions.html#binomial-probability-distribution"><i class="fa fa-check"></i><b>5.5</b> Binomial Probability Distribution</a>
<ul>
<li class="chapter" data-level="5.5.1" data-path="discrete-probability-distributions.html"><a href="discrete-probability-distributions.html#expected-value-of-the-binomial-distribution"><i class="fa fa-check"></i><b>5.5.1</b> Expected Value of the Binomial Distribution</a></li>
<li class="chapter" data-level="5.5.2" data-path="discrete-probability-distributions.html"><a href="discrete-probability-distributions.html#standard-deviation-of-the-binomial-distribution"><i class="fa fa-check"></i><b>5.5.2</b> Standard Deviation of the Binomial Distribution</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="normal-probability-distributions.html"><a href="normal-probability-distributions.html"><i class="fa fa-check"></i><b>6</b> Normal Probability Distributions</a>
<ul>
<li class="chapter" data-level="6.1" data-path="normal-probability-distributions.html"><a href="normal-probability-distributions.html#normal-distribution"><i class="fa fa-check"></i><b>6.1</b> Normal Distribution</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="normal-probability-distributions.html"><a href="normal-probability-distributions.html#standard-normal-distribution"><i class="fa fa-check"></i><b>6.1.1</b> Standard Normal Distribution</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="normal-probability-distributions.html"><a href="normal-probability-distributions.html#sampling-distribution-of-a-statistic"><i class="fa fa-check"></i><b>6.2</b> Sampling Distribution of a Statistic</a>
<ul>
<li class="chapter" data-level="" data-path="normal-probability-distributions.html"><a href="normal-probability-distributions.html#sampling-distribution-of-sample-mean"><i class="fa fa-check"></i>Sampling Distribution of Sample Mean</a></li>
<li class="chapter" data-level="" data-path="normal-probability-distributions.html"><a href="normal-probability-distributions.html#sampling-distribution-of-a-sample-proportion"><i class="fa fa-check"></i>Sampling Distribution of a Sample Proportion</a></li>
<li class="chapter" data-level="" data-path="normal-probability-distributions.html"><a href="normal-probability-distributions.html#sampling-distribution-of-a-sample-variance"><i class="fa fa-check"></i>Sampling Distribution of a Sample Variance</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="normal-probability-distributions.html"><a href="normal-probability-distributions.html#central-limit-theorem"><i class="fa fa-check"></i><b>6.3</b> Central Limit Theorem</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="estimating-parameters-and-determining-sample-sizes.html"><a href="estimating-parameters-and-determining-sample-sizes.html"><i class="fa fa-check"></i><b>7</b> Estimating Parameters and Determining Sample Sizes</a>
<ul>
<li class="chapter" data-level="7.1" data-path="estimating-parameters-and-determining-sample-sizes.html"><a href="estimating-parameters-and-determining-sample-sizes.html#estimate-a-population-proportion"><i class="fa fa-check"></i><b>7.1</b> Estimate a Population Proportion</a></li>
<li class="chapter" data-level="7.2" data-path="estimating-parameters-and-determining-sample-sizes.html"><a href="estimating-parameters-and-determining-sample-sizes.html#confidence-intervals"><i class="fa fa-check"></i><b>7.2</b> Confidence Intervals</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="estimating-parameters-and-determining-sample-sizes.html"><a href="estimating-parameters-and-determining-sample-sizes.html#margin-of-error-me"><i class="fa fa-check"></i><b>7.2.1</b> Margin of Error (ME)</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="estimating-parameters-and-determining-sample-sizes.html"><a href="estimating-parameters-and-determining-sample-sizes.html#finding-the-sample-size-to-estimate-a-population-proportion"><i class="fa fa-check"></i><b>7.3</b> Finding the Sample Size to Estimate a Population Proportion</a></li>
<li class="chapter" data-level="7.4" data-path="estimating-parameters-and-determining-sample-sizes.html"><a href="estimating-parameters-and-determining-sample-sizes.html#estimating-a-population-mean"><i class="fa fa-check"></i><b>7.4</b> Estimating a Population Mean</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="estimating-parameters-and-determining-sample-sizes.html"><a href="estimating-parameters-and-determining-sample-sizes.html#estimating-a-population-mean-when-sigma-is-known"><i class="fa fa-check"></i><b>7.4.1</b> Estimating a Population Mean When <span class="math inline">\(\sigma\)</span> Is Known</a></li>
<li class="chapter" data-level="7.4.2" data-path="estimating-parameters-and-determining-sample-sizes.html"><a href="estimating-parameters-and-determining-sample-sizes.html#estimating-a-population-mean-when-sigma-is-not-known"><i class="fa fa-check"></i><b>7.4.2</b> Estimating a Population Mean When <span class="math inline">\(\sigma\)</span> Is Not Known</a></li>
<li class="chapter" data-level="7.4.3" data-path="estimating-parameters-and-determining-sample-sizes.html"><a href="estimating-parameters-and-determining-sample-sizes.html#t-text-confidence-interval"><i class="fa fa-check"></i><b>7.4.3</b> <span class="math inline">\(t \text { Confidence Interval}\)</span></a></li>
<li class="chapter" data-level="7.4.4" data-path="estimating-parameters-and-determining-sample-sizes.html"><a href="estimating-parameters-and-determining-sample-sizes.html#finding-the-sample-size-to-estimate-a-population-mean"><i class="fa fa-check"></i><b>7.4.4</b> Finding the Sample Size to Estimate a Population Mean</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="estimating-parameters-and-determining-sample-sizes.html"><a href="estimating-parameters-and-determining-sample-sizes.html#estimating-a-population-standard-deviation-or-variance"><i class="fa fa-check"></i><b>7.5</b> Estimating a Population Standard Deviation or Variance</a>
<ul>
<li class="chapter" data-level="7.5.1" data-path="estimating-parameters-and-determining-sample-sizes.html"><a href="estimating-parameters-and-determining-sample-sizes.html#confidence-interval-for-estimating-a-population-standard-deviation-or-variance"><i class="fa fa-check"></i><b>7.5.1</b> Confidence Interval for Estimating a Population Standard Deviation or Variance</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html"><i class="fa fa-check"></i><b>8</b> Hypothesis Testing</a>
<ul>
<li class="chapter" data-level="8.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#hypothesis-testing-1"><i class="fa fa-check"></i><b>8.1</b> Hypothesis Testing</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#type-i-and-type-ii-errors"><i class="fa fa-check"></i><b>8.1.1</b> Type I and Type II Errors</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#inference-for-a-single-proportion"><i class="fa fa-check"></i><b>8.2</b> Inference for a Single Proportion</a></li>
<li class="chapter" data-level="8.3" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#t-text--test-testing-hypothesis-about-mu-with-sigma-not-known"><i class="fa fa-check"></i><b>8.3</b> <span class="math inline">\(t \text {-test}\)</span> | Testing Hypothesis About <span class="math inline">\(\mu\)</span> with <span class="math inline">\(\sigma\)</span> Not Known</a></li>
<li class="chapter" data-level="8.4" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#chi2-text-test-testing-hypothesis-about-a-variance"><i class="fa fa-check"></i><b>8.4</b> <span class="math inline">\(\chi^2 \text{-test}\)</span> | Testing Hypothesis About a Variance</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Introduction to Statistics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="hypothesis-testing" class="section level1" number="8">
<h1><span class="header-section-number">Chapter 8</span> Hypothesis Testing</h1>
<p><strong>Learning Outcome</strong></p>
<table>
<tbody>
<tr class="odd">
<td>Perform hypotheses testing involving a sample mean, proportion, and standard deviation or variance.</td>
</tr>
</tbody>
</table>
<p>This chapter introduces the statistical method of hypothesis testing to test a given claim about a population parameter, such as proportion, mean, standard deviation, or variance. This method combines the concepts learned in the previous chapters, including sampling distribution, standard error, critical scores, and probability theory.</p>
<div id="hypothesis-testing-1" class="section level2" number="8.1">
<h2><span class="header-section-number">8.1</span> Hypothesis Testing</h2>
<p>In statistics, a <strong>hypothesis</strong> is a claim or statement about a property of a population.</p>
<p>A <strong>hypothesis test (or test of significance)</strong> is a procedure for testing a claim about a property of a population.</p>
<p>The <strong>null hypothesis (<span class="math inline">\(H_0\)</span>)</strong> is a statement that the value of a population parameter (such as proportion, mean, or standard deviation) is equal to some claimed value.</p>
<p>The <strong>alternative hypothesis (<span class="math inline">\(H_A\)</span>)</strong> is a statement that the parameter has a value that somehow differs from the null hypothesis.</p>
<p><strong>Example:</strong></p>
<p>Probability of getting head from a single toss of coin, <span class="math inline">\(p = 0.5\)</span>.</p>
<p>Therefore, expected value of the number of heads from <span class="math inline">\(20\)</span> tosses = <span class="math inline">\(10\)</span>.</p>
<p>Suppose, you have tossed a coin <span class="math inline">\(20\)</span> times and seen <span class="math inline">\(15\)</span> heads, <span class="math inline">\(\hat p = 0.75\)</span>.</p>
<p><strong>Is the coin fair, or is it biased towards heads?</strong></p>
<div id="null-and-alternative-hypotheses" class="section level4 unnumbered">
<h4>Null and Alternative Hypotheses</h4>
<p>Null hypothesis <span class="math inline">\((H_0)\)</span>: states that any deviation from what was expected is due to chance error (i.e. the coin is fair).</p>
<p>Alternative hypothesis <span class="math inline">\((H_A)\)</span>: asserts that the observed deviation is too large to be explained by chance alone (i.e. the coin is biased towards heads).</p>
<p><span class="math display">\[
H_0: p = 0.5 \\
H_A: p &gt; 0.5
\]</span></p>
<p>Now, what is the probability of <span class="math inline">\(p \ge 0.75?\)</span></p>
<p>From normal approximation of the sampling distribution of <span class="math inline">\(\hat p\)</span>,</p>
<p><span class="math display">\[
\begin{align}
p &amp;= 0.5 \\
se &amp;= \sqrt{(0.5)(0.5)/20} = 0.112 \\
z &amp;= (0.75 - 0.50)/0.112 = 2.236  \\ \\
P(z\ge2.236) &amp;= 0.0127 \Leftarrow \text {this probability is also called p-value} 
\end{align}
\]</span>
Hence, there is only <span class="math inline">\(1.27\%\)</span> probability that observing <span class="math inline">\(15\)</span> heads from <span class="math inline">\(20\)</span> tosses is merely a chance. Then the question is, if the coin is indeed fair, is the p-value too small?</p>
</div>
<div id="interpretation-of-textp-value" class="section level4 unnumbered">
<h4>Interpretation of <span class="math inline">\(\text{p-value}\)</span></h4>
<ul>
<li><p>A <span class="math inline">\(\text{p-value}\)</span> is the probability of obtaining the observed effect (or larger) under a “null hypothesis”. Thus, a <span class="math inline">\(\text{p-value}\)</span> that is very small indicates that the observed effect is very unlikely to have arisen purely by chance, and therefore provides evidence against the null hypothesis.</p></li>
<li><p>It has been common practice to interpret a <span class="math inline">\(\text{p-value}\)</span> by examining whether it is smaller than particular threshold values or <strong>“significance level”.</strong> In particular, <span class="math inline">\(\text{p-values}\)</span> less than <span class="math inline">\(5\%\)</span> are often reported as “statistically significant”, and interpreted as being small enough to justify rejection of the null hypothesis.
By definition, the significance level <span class="math inline">\(\alpha\)</span> is the probability of mistakenly rejecting the null hypothesis when it is true.</p></li>
</ul>
<p><span class="math display">\[\textbf {Significance level } \alpha = P \textbf { (rejecting  } H_0 \textbf { when } H_0 \textbf { is true)} \]</span></p>
<p>In common practice, <span class="math inline">\(\alpha\)</span> is set at <span class="math inline">\(10\%, 5\%\)</span> or <span class="math inline">\(1\%\)</span>.</p>
<p>In the coin toss example:</p>
<blockquote>
<p>p-value = <span class="math inline">\(1.27\%\)</span> which is less than the <span class="math inline">\(5\%\)</span> significance level.</p>
</blockquote>
<blockquote>
<p>Therefore, the result is statistically significant.</p>
</blockquote>
<blockquote>
<p>Conclusion: The coin is biased towards heads.</p>
</blockquote>
</div>
<div id="critical-value-method" class="section level4 unnumbered">
<h4>Critical Value Method</h4>
<p>In a hypothesis test, the <strong>critical value(s)</strong> separates the critical region (where we reject the null hypothesis) from the values of the test statistic that do not lead to rejection of the null hypothesis.</p>
<p>With the critical value method of testing hypothesis, we make a decision by comparing the test statistic to the critical value(s).</p>
<p><img src="critical_z_value.png" /></p>
</div>
<div id="one-sided-and-two-sided-tests" class="section level4 unnumbered">
<h4>One-sided and two-sided tests</h4>
<p>If the researchers are only interested in showing an increase or a decrease, but not
both, use a <strong>one-sided test</strong>. If the researchers would be interested in any difference
from the null value - an increase or decrease - then the test should be <strong>two-sided</strong>.</p>
<p>After observing data, it is tempting to turn a two-sided test into a one-sided test.
Hypotheses must be set up before observing the data. If they are not, the test must be two-sided.</p>
<p><img src="sidedness_example_figures.png" width="800px" /></p>
</div>
<div id="type-i-and-type-ii-errors" class="section level3" number="8.1.1">
<h3><span class="header-section-number">8.1.1</span> Type I and Type II Errors</h3>
<p>When testing a null hypothesis, sometimes the test comes to a wrong conclusion by rejecting it or failing to reject it. There are two kinds of errors: <strong>type I</strong> and <strong>type II</strong> errors.</p>
<ul>
<li><span class="math inline">\(\textbf {Type I error} :\)</span> The error of rejecting the null hypothesis when it is actually true.</li>
</ul>
<p><span class="math inline">\(\alpha = P (\textbf{type I error}) = P (\text{rejecting } H_0 \text{ when } H_0 \text{ is true } )\)</span></p>
<blockquote>
<p>The probability of <span class="math inline">\(\text {Type I}\)</span> can be minimized by choosing a smaller <span class="math inline">\(\alpha\)</span>.</p>
</blockquote>
<ul>
<li><span class="math inline">\(\textbf {Type II error} :\)</span> The error of failing to reject the null hypothesis when it is actually false.</li>
</ul>
<p><span class="math inline">\(\beta = P (\textbf{type II error}) = P (\text{failing to reject } H_0 \text{ when } H_0 \text{ is false} )\)</span></p>
<blockquote>
<p>The probability of <span class="math inline">\(\text {Type II}\)</span> can be minimized by choosing a larger sample size <span class="math inline">\(n\)</span>.</p>
</blockquote>
<div id="power-of-a-hypothesis-test" class="section level5 unnumbered">
<h5>Power of a Hypothesis Test</h5>
<p>The <strong>power</strong> of a hypothesis test is the probability <span class="math inline">\(1-\beta\)</span> of rejecting a false null hypothesis. The value of the power is computed by using a particular significance level <span class="math inline">\(\alpha\)</span> and a particular value of the population parameter that is an alternative to the value of assumed true in the null hypothesis.</p>
<p>In practice, statistical studies are commonly designed with a statistical power of at least <span class="math inline">\(80%\)</span>.</p>
<div class="figure">
<img src="statistical_power.png" alt="" />
<p class="caption">Figure: Statistical Power</p>
</div>
<p><strong>Post-hoc Power Calculation for One Study Group vs. Population</strong></p>
<p>Suppose,</p>
<p><span class="math display">\[
H_0 : p = P_0  \\
H_A : p \ne P_0  \\
\]</span>
<span class="math display">\[
\begin{align}
P_0 &amp;= \text{proportion of population} \\
P_1 &amp;= \text{proportion observed from the data (an alternative population)}  \\
N &amp;= \text{sample size} \\
\alpha &amp;= \text{probability of type I error}  \\
\beta &amp;= \text{probability of type II error}  \\
z &amp;= \text{critical z score for a given } \alpha \text { or } \beta 
\end{align}
\]</span></p>
<p>Suppose, <span class="math inline">\(P_1\)</span> is an alternative to the value assumed in <span class="math inline">\(H_0\)</span>.</p>
<p>Under <span class="math inline">\(H_0\)</span>,</p>
<p><span class="math display">\[
P&#39;_0 = P_0 + z_{1-\alpha/2} \cdot \sqrt{\dfrac{P_0Q_0}{N}}
\]</span></p>
<p>Under <span class="math inline">\(H_A\)</span>,</p>
<p><span class="math display">\[
\therefore z_{\beta} = \dfrac{P&#39;_0 - P_1}{\sqrt{\dfrac{P_1Q_1}{N}}} = \dfrac{\Bigg( P_0 + z_{1-\alpha/2} \cdot \sqrt{\dfrac{P_0Q_0}{N}} \Bigg) - P_1}{\sqrt{\dfrac{P_1Q_1}{N}}}  \\
\\
P(\textbf{Type II error}) = 
\beta = \Phi \left \{ \dfrac{\Bigg( P_0 + z_{1-\alpha/2} \cdot \sqrt{\dfrac{P_0Q_0}{N}} \Bigg) - P_1}{\sqrt{\dfrac{P_1Q_1}{N}}}  \right \} 
\\
\]</span></p>
<p><span class="math display">\[
\begin{align}
\text{where,} \\
Q_0 &amp;= 1 - P_0 \\
Q_1 &amp;= 1 - P_1 \\
\Phi &amp;= \text{cumulative normal distribution function}
\end{align}
\]</span></p>
<p><strong>Example: Calculate statistical power for various alternative hypotheses.</strong></p>
<p><span class="math display">\[
Suppose,
\begin{cases}
H_0: p = 0.5  \\
H_A: p \ne 0.5  \\
P(\text{type I error}) = \alpha = 0.05 \\
\text{Critical z score, } z_{1 - \alpha/2} = 1.96 \\
N = 14  \\
\end{cases}
\]</span></p>
<p><span class="math display">\[
\begin{array}{r|r|r}
           P_1 &amp;  \Phi(z_{\beta}) = \beta    &amp; 1-\beta     \\ \hline
           0.6 &amp;  \Phi(1.2367)  = 0.8919       &amp; 0.1081      \\
           0.7 &amp;  \Phi(0.5055)  = 0.6934       &amp; 0.3066      \\
           0.8 &amp;  \Phi(-0.3562) = 0.3608       &amp; 0.6392      \\
           0.9 &amp;  \Phi(-1.7222) = 0.0425       &amp; 0.9575      \\ \hline
\end{array}
\]</span></p>
<p><strong>Example: Sample size calculation to achieve power (when <span class="math inline">\(P_0\)</span> and <span class="math inline">\(P_1\)</span> are known)</strong></p>
<p><span class="math display">\[
\begin{align}
z_{\beta} = \Phi^{-1}(\beta) &amp;= \dfrac{\Bigg( P_0 + z_{1-\alpha/2} \cdot \sqrt{\dfrac{P_0Q_0}{N}} \Bigg) - P_1}{\sqrt{\dfrac{P_1Q_1}{N}}} \\
\\
z_{1-\alpha/2} &amp;= 1.96  \\
1- \beta &amp;= 0.8  \\
\\
\Phi^{-1}(0.2) = -0.84 &amp;= \dfrac{\Bigg( 0.5 + 1.96 \cdot \sqrt{\dfrac{(0.5) (0.5)}{N}} \Bigg) - 0.9}{\sqrt{\dfrac{(0.9)(0.1)}{N}}} \\
\implies N &amp;= \Bigg( \dfrac{1.96\sqrt{0.25} + 0.84\sqrt{0.09}}{0.4}  \Bigg)^2  \\
&amp;\approx 10 
\end{align}
\]</span></p>
<p><strong>Example: Sample size calculation to achieve power (when <span class="math inline">\(P_0\)</span> and <span class="math inline">\(P_1\)</span> are unknown)</strong></p>
<p><span class="math display">\[
N = \Bigg(  \dfrac{z_{1-\alpha/2} + z_{1-\beta}}{ES} \Bigg)^2   \\
\]</span>
where,</p>
<p><span class="math display">\[
\text{effect size, } ES = \dfrac{|P_1-P_0|}{\sqrt{P_0Q_0}}
\]</span></p>
<table>
<tbody>
<tr class="odd">
<td><strong>Statistical power and design of experiment:</strong> When designing an experiment, it is essential to determine the minimize sample size that would be needed to detect an acceptable difference between the true value of the population parameter and what is observed from the data. A <span class="math inline">\(5\%\)</span> significance level <span class="math inline">\((\alpha)\)</span> and a statistical power of at least <span class="math inline">\(80\%\)</span> are common requirements for determining that a hypothesis test is effective.</td>
</tr>
</tbody>
</table>
</div>
<div id="formal-test-of-hypothesis" class="section level4 unnumbered">
<h4>Formal Test of Hypothesis</h4>
<p>Follow these seven steps when carrying out a hypothesis test.</p>
<ol style="list-style-type: decimal">
<li><p>State the name of the test being used.<br />
</p></li>
<li><p>Verify conditions to ensure the standard error estimate is reasonable and the
point estimate follows the appropriate distribution and is unbiased.<br />
</p></li>
<li><p>Write the hypotheses and set them up in mathematical notation.<br />
</p></li>
<li><p>Identify the significance level <span class="math inline">\(\alpha\)</span>.<br />
</p></li>
<li><p>Calculate the test statistics (e.g. <span class="math inline">\(z\)</span>), using an appropriate point estimate of the paramater of interest and its standard error.
<span class="math display">\[\text{test statistics} = \frac{\text{point estimate - null value}}{\text{SE of estimate}}\]</span></p></li>
<li><p>Find the <span class="math inline">\(\text{p-value}\)</span>, compare it to <span class="math inline">\(\alpha\)</span>, and state whether to reject or not reject the null hypothesis.<br />
</p></li>
<li><p>Write your conclusion in context.</p></li>
</ol>
</div>
</div>
</div>
<div id="inference-for-a-single-proportion" class="section level2" number="8.2">
<h2><span class="header-section-number">8.2</span> Inference for a Single Proportion</h2>
<p><span style="color:#08519c"> <strong>Conditions of the sampling distributions of <span class="math inline">\(\hat p\)</span> being nearly normal</strong> </span></p>
<p>The sampling distribution for <span class="math inline">\(\hat p\)</span>, taken from a sample of size <span class="math inline">\(n\)</span> from a population with a true proportion <span class="math inline">\(p\)</span>, is nearly normal when</p>
<ol style="list-style-type: decimal">
<li>the sample observations are independent and<br />
</li>
<li>we expect to see at least <span class="math inline">\(10\)</span> successes and <span class="math inline">\(10\)</span> failures in our sample, i.e. <span class="math inline">\(np \ge 10\)</span> and <span class="math inline">\(n(1-p) \ge 10\)</span>. This is called the <strong>success-failure condition.</strong></li>
</ol>
<p>If the conditions are met, then the sampling distribution of <span class="math inline">\(\hat p\)</span> is nearly normal with mean <span class="math inline">\(\mu_{\hat p} = p\)</span> and standard deviation <span class="math inline">\(\sigma_{\hat p} = \sqrt \frac{p(1-p)}{n}\)</span>.</p>
<p><strong>Example 1:</strong></p>
<p><strong>The DMV claims that <span class="math inline">\(80\%\)</span> of all drivers pass the driving test. In a survey of <span class="math inline">\(90\)</span> teens, only <span class="math inline">\(61\)</span> passed. Is there evidence that teen pass rates are significantly below <span class="math inline">\(80\%?\)</span></strong></p>
<p>Let’s say, <span class="math inline">\(p\)</span> is the true population proportion.</p>
<p><span class="math display">\[
\begin{align}
\text {One-tailed test} &amp;:\\
H_0&amp;: p = 0.80   \\
H_A&amp;: p &lt; 0.80
\end{align}
\]</span></p>
<p>Verify success-failure condition:<br />
<span class="math display">\[
\begin{align}
np \ge 10 \rightarrow 90 \times 0.80 \ge 10 \\
n(1-p) \ge 10 \rightarrow 90 \times (1-0.80) \ge 10
\end{align}
\]</span></p>
<p>Therefore, the conditions for a normal model are met.</p>
<p>Now,
<span class="math display">\[
\begin{align}
\hat p &amp;= \frac {61}{90} = 0.678 \\ \\
SD(\hat p) &amp;= \sqrt \frac{p_0q_0}{n} = \sqrt \frac{(0.80)(0.20)}{90} = 0.042  \\ \\
z &amp;= \frac {0.678-0.80}{0.042} = -2.90   \\ \\
p\text{-value} &amp;= P(z &lt; -2.90) = 0.002 &lt; 0.05 
\end{align}
\]</span></p>
<p>Hence, we reject <span class="math inline">\(H_0\)</span>. Teen pass rate is significantly below population pass rate.</p>
<p><strong>Example 2:</strong></p>
<p><strong>Under natural conditions, <span class="math inline">\(51.7\%\)</span> of births are male. In Punjab India’s hospital <span class="math inline">\(56.9\%\)</span> of the <span class="math inline">\(550\)</span> births were male. Is there evidence that the proportion of male births is significantly different for this hospital?</strong></p>
<p><span class="math display">\[
\begin{align}
\text {Two-tailed test} &amp;:\\
H_0&amp;: p = 0.517   \\
H_A&amp;: p \ne 0.517
\end{align}
\]</span></p>
<p>Verify success-failure condition:<br />
<span class="math display">\[
\begin{align}
np \ge 10 \rightarrow 550 \times 0.517 \ge 10 \\
n(1-p) \ge 10 \rightarrow 550 \times (1-0.517) \ge 10
\end{align}
\]</span></p>
<p><span class="math display">\[
\begin{align}
\hat p &amp;= 0.569 \\ \\
SD(\hat p) &amp;= \sqrt \frac{p_0q_0}{n} = \sqrt \frac{(0.517)(1-0.517)}{550} = 0.0213  \\ \\
z &amp;= \frac {0.569-0.517}{0.0213} = 2.44   \\ \\
p\text{-value} &amp;= 2 \times P(z &gt; 2.44) = 2 \times 0.0073 = 0.0146 &lt; 0.05 
\end{align}
\]</span></p>
<p>Hence, we reject <span class="math inline">\(H_0\)</span>. Male birth rate is significantly higher at the hospital than the natural birth rate.</p>
</div>
<div id="t-text--test-testing-hypothesis-about-mu-with-sigma-not-known" class="section level2" number="8.3">
<h2><span class="header-section-number">8.3</span> <span class="math inline">\(t \text {-test}\)</span> | Testing Hypothesis About <span class="math inline">\(\mu\)</span> with <span class="math inline">\(\sigma\)</span> Not Known</h2>
<p><strong>Example 1:</strong></p>
<p><strong>Average weight of a mice population of a particular breed and age is <span class="math inline">\(30 \text{ gm}\)</span>. Weights recorded from a random sample of <span class="math inline">\(5\)</span> mice from that population are <span class="math inline">\({31.8, 30.9, 34.2, 32.1, 28.8}.\)</span> Test whether the sample mean is significantly greater than the population mean.</strong></p>
<p><span class="math display">\[
\begin{align}
H_0&amp;: \mu = 30   \\
H_A&amp;: \mu &gt; 30   \\ \\
\bar x &amp;= 31.56 \\
s &amp;= 1.9604 \\
SE(\bar x) &amp;= 1.9604/\sqrt 5 = 0.8767 \\ \\
t &amp;= (31.56 - 30)/0.8767 = 1.779 \\
df &amp;= (5 -1) = 4 \\
p-value &amp;= 7.5\% &gt; 5\%
\end{align}
\]</span></p>
<p>Conclusion: <span class="math inline">\(H_0\)</span> cannot be rejected. The sample mean is not significantly greater than the population mean.</p>
<p><strong>Example 2:</strong></p>
<p><strong>EPA recommended mirex screening is 0.08 ppm. A study of a sample of 150 salmon found an average mirex concentration of 0.0913 ppm with a std. deviation of 0.0495 ppm. Are farmed salmon contaminated beyond the permitted EPA level? Also, find a <span class="math inline">\(95\%\)</span> confidence interval for the mirex concentration in salmon.</strong></p>
<p><span class="math display">\[
\begin{align}
H_0&amp;: \mu = 0.08   \\
H_A&amp;: \mu &gt; 0.08   \\ \\
\bar x &amp;= 0.0913 \\
s &amp;= 0.0495 \\
SE(\bar x) &amp;= 0.0495/\sqrt {150} = 0.0040 \\ \\
t_{149} &amp;= \dfrac{\bar x - \mu}{SE(\bar x)} = \dfrac{(0.0913 - 0.08)}{0.0040} = 2.795 \\
df &amp;= (150 -1) = 149 \\
p-value &amp;= P(t_{149}&gt;2.795)= 0.29\% &lt; 5\%
\end{align}
\]</span></p>
<p>Conclusion: Reject <span class="math inline">\(H_0\)</span>. The sample mean mirex level significantly higher that the EPA screening level.</p>
</div>
<div id="chi2-text-test-testing-hypothesis-about-a-variance" class="section level2" number="8.4">
<h2><span class="header-section-number">8.4</span> <span class="math inline">\(\chi^2 \text{-test}\)</span> | Testing Hypothesis About a Variance</h2>
<p>Listed below are the heights (cm) for the simple random sample of female supermodels. Use a <span class="math inline">\(0.01\)</span> significance level to test the claim that supermodels have heights with a standard deviation that is less than <span class="math inline">\(\sigma=7.5 \text { cm}\)</span> for the population of women. Does it appear that heights of supermodels vary less than heights of women from the population?</p>
<p><span class="math display">\[
\text{178, 177, 176, 174, 175, 178, 175, 178} \\ 
\text{178, 177, 180, 176, 180, 178, 180, 176}  \\
s^2 = 3.4
\]</span></p>
<p><span class="math display">\[
\begin{align}
H_0: \sigma^2 = 56.25 \\
H_A: \sigma^2 &lt; 56.25 \\\\
\chi^2 = (n-1)\frac{s^2}{\sigma^2} &amp;= (15)\frac{(3.4)}{(56.25)} \\  
       &amp;= 0.907 \\ \\
\end{align}
\]</span>
<img src="chi_squared_test.png" /></p>
<p>From <span class="math inline">\(\chi^2\)</span> table,</p>
<p><span class="math display">\[
\text {The critical value of } \chi^2 = 5.229 \text { at }  \alpha = 0.01.  \\
\]</span>
Hence, we reject <span class="math inline">\(H_0\)</span>.</p>
<p><strong>Confidence Interval Calculation:</strong></p>
<p><span class="math display">\[
\sqrt{ \dfrac{(n-1)s^2}{\chi_R^2} } &lt; \sigma  &lt; \sqrt{ \dfrac{(n-1)s^2}{\chi_L^2} }  \\
\sqrt{ \dfrac{(16-1)3.4}{30.578} } &lt; \sigma  &lt; \sqrt{ \dfrac{(16-1)3.4}{5.229} }  \\
1.3 \text{ cm } &lt; \sigma &lt; 3.1 \text { cm }
\]</span></p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="estimating-parameters-and-determining-sample-sizes.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "serif",
"size": 3
},
"edit": {
"link": "https://github.com/amlanbanerjee/introduction_to_statistics/edit/master/08-hypothesis_testing.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": "https://github.com/amlanbanerjee/introduction_to_statistics/blob/master/08-hypothesis_testing.Rmd",
"text": null
},
"download": "book.pdf",
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
